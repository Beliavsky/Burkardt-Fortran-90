<html>

  <head>
    <title>
      TEST_OPT - Scalar Function Optimization Test Problems
    </title>
  </head>

  <body bgcolor="#EEEEEE" link="#CC0000" alink="#FF3300" vlink="#000055">

    <h1 align = "center">
      TEST_OPT <br> Optimization of a Scalar Function <br> Test Problems
    </h1>

    <hr>

    <p>
      <b>TEST_OPT</b>,
      a FORTRAN90 code which 
      defines test problems for the scalar function optimization problem. 
    </p>

    <p>
      The scalar function optimization problem is to find a value
      for the N-dimensional vector X which minimizes the value of
      the given scalar function <b>F(X)</b>.  The function <b>F(X)</b> is 
      not usually defined as the sum of squares of other functions.  
      The minimum function value is not guaranteed to be zero.  
    </p>

    <p>
      Any system of M nonlinear functions in N unknowns can be turned into
      a scalar optimization problem.  One way to do this is to define the functional
      <b>F(X)</b> to be the sum of the squares of the original nonlinear functions.
      The minimizer of <b>F</b> will then minimize the sum of the squares of the
      residuals.  Since this process involves squaring, it can be less accurate
      than dealing directly with the original nonlinear functions: that is to say,
      the derived optimization problem may be more convenient to solve, but might
      provide less accurate results than applying a nonlinear solver to the original
      system.
    </p>

    <p>
      If a function <b>F(X)</b> is differentiable, then at an optimum, the
      gradient vector must vanish.  Thus, it is also possible to start with an
      optimization problem involving <b>F(X)</b> and turn it into a problem in
      which we seek a zero of the nonlinear functions represented by the gradient
      of <b>F</b>.  Of course, the gradient must be zero at a mininum, but 
      the converse does not hold; thus unless we know more about <b>F</b>, it is not
      safe to try to replace the optimization problem by a nonlinear function
      solution.
    </p>

    <p>
      For each test problem, routines are provided to evaluate the function,
      gradient vector, and hessian matrix.  Routines are also provided to
      indicate the number of variables, the problem title, a suitable starting 
      point, and a minimizing solution, if known.
    </p>

    <p>
      The functions defined include:
      <ol>
        <li>
          The Fletcher-Powell helical valley function,<br>
          N = 3.
        </li>
        <li>
          The Biggs EXP6 function,<br>
          N = 6.
        </li>
        <li>
          The Gaussian function,<br>
          N = 3.
        </li>
        <li>
          The Powell badly scaled function,<br>
          N = 2.
        </li>
        <li>
          The Box 3-dimensional function,<br>
          N = 3.
        </li>
        <li>
          The variably dimensioned function,<br>
          1 &lt;= N.
        </li>
        <li>
          The Watson function,<br>
          2 &lt;= N.
        </li>
        <li>
          The penalty function #1,<br>
          1 &lt;= N.
        </li>
        <li>
          The penalty function #2,<br>
          1 &lt;= N.
        </li>
        <li>
          The Brown badly scaled function,<br>
          N = 2.
        </li>
        <li>
          The Brown and Dennis function,<br>
          N = 4.
        </li>
        <li>
          The Gulf R&D function,<br>
          N = 3.
        </li>
        <li>
          The trigonometric function,<br>
          1 &lt;= N.
        </li>
        <li>
          The extended Rosenbrock parabolic valley function,<br>
          1 &lt;= N.
        </li>
        <li>
          The extended Powell singular quartic function,<br>
          4 &lt;= N.
        </li>
        <li>
          The Beale function,<br>
          N = 2.
        </li>
        <li>
          The Wood function,<br>
          N = 4.
        </li>
        <li>
          The Chebyquad function,<br>
          1 &lt;= N.
        </li>
        <li>
          Leon's cubic valley function,<br>
          N = 2.
        </li>
        <li>
          Gregory and Karney's Tridiagonal Matrix Function,<br>
          1 &lt;= N.
        </li>
        <li>
          The Hilbert function,<br>
          1 &lt;= N.
        </li>
        <li>
          The De Jong Function F1,<br>
          N = 3.
        </li>
        <li>
          The De Jong Function F2,<br>
          N = 2.
        </li>
        <li>
          The De Jong Function F3 (discontinuous),<br>
          N = 5.
        </li>
        <li>
          The De Jong Function F4 (Gaussian noise),<br>
          N = 30.
        </li>
        <li>
          The De Jong Function F5,<br>
          N = 2.
        </li>
        <li>
          The Schaffer Function F6,<br>
          N = 2.
        </li>
        <li>
          The Schaffer Function F7,<br>
          N = 2.
        </li>
        <li>
          The Goldstein Price Polynomial,<br>
          N = 2.
        </li>
        <li>
          The Branin RCOS Function,<br>
          N = 2.
        </li>
        <li>
          The Shekel SQRN5 Function,<br>
          N = 4.
        </li>
        <li>
          The Shekel SQRN7 Function,<br>
          N = 4.
        </li>
        <li>
          The Shekel SQRN10 Function,<br>
          N = 4.
        </li>
        <li>
          The Six-Hump Camel-Back Polynomial,<br>
          N = 2.
        </li>
        <li>
          The Shubert Function,<br>
          N = 2.
        </li>
        <li>
          The Stuckman Function,<br>
          N = 2.
        </li>
        <li>
          The Easom Function,<br>
          N = 2.
        </li>
        <li>
          The Bohachevsky Function #1,<br>
          N = 2.
        </li>
        <li>
          The Bohachevsky Function #2,<br>
          N = 2.
        </li>
        <li>
          The Bohachevsky Function #3,<br>
          N = 2.
        </li>
        <li>
          The Colville Polynomial,<br>
          N = 4.
        </li>
        <li>
          The Powell 3D function,<br>
          N = 3.
        </li>
        <li>
          The Himmelblau function,<br>
          N = 2.
        </li>
      </ol>
    </p>

    <h3 align = "center">
      Licensing:
    </h3>

    <p>
      The computer code and data files described and made available on this web page 
      are distributed under
      <a href = "https://www.gnu.org/licenses/lgpl-3.0.en.html">the GNU LGPL license.</a>
    </p>

    <h3 align = "center">
      Languages:
    </h3>

    <p>
      <b>TEST_OPT</b> is available in
      <a href = "../../f_src/test_opt/test_opt.html">a FORTRAN90 version</a> and
      <a href = "../../m_src/test_opt/test_opt.html">a MATLAB version</a>.
    </p>

    <h3 align = "center">
      Related Data and Programs:
    </h3>

    <p>
      <a href = "../../f_src/asa047/asa047.html">
      ASA047</a>,
      a FORTRAN90 code which
      minimizes a scalar function of several variables using the Nelder-Mead
      algorithm.
    </p>

    <p>
      <a href = "../../f_src/brent/brent.html">
      BRENT</a>,
      a FORTRAN90 code which
      contains Richard Brent's routines for finding the zero, local minimizer,
      or global minimizer of a scalar function of a scalar argument, without
      the use of derivative information.
    </p>

    <p>
      <a href = "../../f_src/compass_search/compass_search.html">
      COMPASS_SEARCH</a>,
      a FORTRAN90 code which 
      seeks the minimizer of a scalar function of several variables
      using compass search, a direct search algorithm that does not use derivatives.
    </p>

    <p>
      <a href = "../../f_src/dqed/dqed.html">
      DQED</a>,
      a FORTRAN90 code which
      solves constrained least squares problems.
    </p>

    <p>
      <a href = "../../f_src/nl2sol/nl2sol.html">
      NL2SOL</a>,
      a FORTRAN90 code which 
      implements an adaptive nonlinear least-squares algorithm.
    </p>

    <p>
      <a href = "../../f_src/praxis/praxis.html">
      PRAXIS</a>,
      a FORTRAN90 code which
      minimizes a scalar
      function of several variables.
    </p>

    <p>
      <a href = "../../f_src/test_nls/test_nls.html">
      TEST_NLS</a>,
      a FORTRAN90 code which
      defines a number of problems for nonlinear least squares solvers.
    </p>

    <p>
      <a href = "../../f_src/test_nonlin/test_nonlin.html">
      TEST_NONLIN</a>,
      a FORTRAN90 code which
      defines a number of problems for nonlinear equation solvers.
    </p>

    <p>
      <a href = "../../f_src/test_opt_test/test_opt_test.html">
      test_opt_test</a>
    </p>

    <p>
      <a href = "../../f_src/test_opt_con/test_opt_con.html">
      TEST_OPT_CON</a>,
      a FORTRAN90 code which
      defines test problems for the minimization of a scalar function
      of several variables, with the search constrained to lie within a 
      specified hyper-rectangle.
    </p>

    <p>
      <a href = "../../f_src/test_optimization/test_optimization.html">
      TEST_OPTIMIZATION</a>,
      a FORTRAN90 code which
      defines test problems for the minimization of a scalar function
      of several variables, as described by Molga and Smutnicki.
    </p>

    <p>
      <a href = "../../f_src/toms611/toms611.html">
      TOMS611</a>,
      a FORTRAN90 code which
      minimizes a scalar functional of multiple variables.
    </p>

    <h3 align = "center">
      Reference:
    </h3>

    <p>
      <ol>   
        <li>
          John Dennis, Robert Schnabel,<br>
          Numerical Methods for Unconstrained Optimization 
          and Nonlinear Equations,<br>
          SIAM, 1996,<br>
          ISBN13: 978-0-898713-64-0,<br>
          LC: QA402.5.D44.
        </li>
      </ol>
    </p>
 
    <h3 align = "center">
      Source Code:
    </h3>

    <p>
      <ul>
        <li>
          <a href = "test_opt.f90">test_opt.f90</a>, the source code.
        </li>
        <li>
          <a href = "test_opt.sh">test_opt.sh</a>, compiles the source code.
        </li>
      </ul>
    </p>

    <hr>

    <i>
      Last revised on 04 September 2020.
    </i>

    <!-- John Burkardt -->

  </body>

</html>
